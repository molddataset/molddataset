{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ae2c3e",
   "metadata": {},
   "source": [
    "<h1 style=\"color: orange; font-size: 48px;\">SAM</h1>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c7824",
   "metadata": {},
   "source": [
    " <font color='orange'>1. Instalación del modelo</font>\n",
    "\n",
    " * Se importa el modelo base >> from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    " * Este modelo NO se entrena, ni está diseñado para esto\n",
    "\n",
    " * Se usa el modleo vit_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dcfbc9",
   "metadata": {},
   "source": [
    " <font color='orange'>2. Inferencia sobre el modelo SAM</font>\n",
    "\n",
    " * SAM viene pre entrenado con millones de imágenes, es capaz él solo de segmentar elementos en una imagen.\n",
    "\n",
    " * Se muestra la aplicación se SAM pasandole como prompt o entrada, las cajas de YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3d57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelos YOLO y SAM...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "# ---------------------- CONFIGURACIÓN ----------------------\n",
    "input_dir = r\"C:\\Users\\adina\\OneDrive\\Documentos\\TFM\\new\\dataset_etiquetado_split\\yolo\\data\\test\"\n",
    "yolo_model_path = r\"C:\\Users\\adina\\OneDrive\\Documentos\\TFM\\new\\yolo_640\\runs\\train\\yolov8_mold_finetune\\weights\\best.pt\"\n",
    "sam_checkpoint = r\"C:\\Users\\adina\\OneDrive\\Documentos\\TFM\\Preprocesado\\Finetuning\\sam\\sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "iou_thresh = 0.15\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Función para calcular IoU\n",
    "def calcular_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "    if interArea == 0:\n",
    "        return 0.0\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    return interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "# Cargar modelos\n",
    "print(\"Cargando modelos YOLO y SAM...\")\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Inicializar métricas globales\n",
    "tp_total = 0\n",
    "fp_total = 0\n",
    "fn_total = 0\n",
    "\n",
    "# Procesar cada imagen\n",
    "for img_name in sorted(os.listdir(input_dir)):\n",
    "    if not img_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "        continue\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    lbl_path = os.path.splitext(img_path)[0] + \".txt\"\n",
    "\n",
    "    # Leer y preparar imagen\n",
    "    orig = cv2.imread(img_path)\n",
    "    h, w = orig.shape[:2]\n",
    "    rgb = cv2.cvtColor(orig.copy(), cv2.COLOR_BGR2RGB)\n",
    "    predictor.set_image(rgb)\n",
    "\n",
    "    # Leer cajas ground-truth\n",
    "    gt_boxes = []\n",
    "    if os.path.exists(lbl_path):\n",
    "        with open(lbl_path) as f:\n",
    "            for line in f:\n",
    "                cls, xc, yc, bw, bh = map(float, line.split())\n",
    "                x1 = int((xc - bw/2) * w)\n",
    "                y1 = int((yc - bh/2) * h)\n",
    "                x2 = int((xc + bw/2) * w)\n",
    "                y2 = int((yc + bh/2) * h)\n",
    "                gt_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    # Predicción YOLO\n",
    "    results = yolo_model.predict(img_path, imgsz=640, conf=0.20, verbose=False)\n",
    "    pred_boxes = [[int(x1), int(y1), int(x2), int(y2)] for x1, y1, x2, y2 in results[0].boxes.xyxy.cpu().numpy()]\n",
    "\n",
    "    # Calcular métricas por imagen\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for box in pred_boxes:\n",
    "        max_iou = max([calcular_iou(box, gt) for gt in gt_boxes] or [0])\n",
    "        if max_iou >= iou_thresh:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    fn = len(gt_boxes) - tp\n",
    "\n",
    "    tp_total += tp\n",
    "    fp_total += fp\n",
    "    fn_total += fn\n",
    "\n",
    "    # Filtrar buenas para SAM\n",
    "    good_boxes = [box for box in pred_boxes if max([calcular_iou(box, gt) for gt in gt_boxes] or [0]) >= iou_thresh]\n",
    "\n",
    "    # Crear overlay con detecciones y máscaras\n",
    "    overlay = rgb.copy()\n",
    "    # Dibujar cajas YOLO\n",
    "    for box in pred_boxes:\n",
    "        max_iou = max([calcular_iou(box, gt) for gt in gt_boxes] or [0])\n",
    "        color = (0, 0, 255) if max_iou >= iou_thresh else (255, 0, 0)\n",
    "        cv2.rectangle(overlay, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "\n",
    "    # Superponer máscaras SAM en verde\n",
    "    for box in good_boxes:\n",
    "        box_arr = np.array([box])\n",
    "        masks, scores, _ = predictor.predict(box=box_arr, multimask_output=False)\n",
    "        mask = masks[0]\n",
    "        overlay[mask] = (overlay[mask] * 0.5 + np.array([0, 255, 0]) * 0.5).astype(np.uint8)\n",
    "\n",
    "    # Mostrar resultado combinado\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(f\"{img_name} - YOLO+SAM: azul=TP rojo=FP verde=mask\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Cálculo métricas finales\n",
    "accuracy_total = tp_total / (tp_total + fp_total + fn_total) if (tp_total + fp_total + fn_total) > 0 else 0\n",
    "precision_total = tp_total / (tp_total + fp_total) if (tp_total + fp_total) > 0 else 0\n",
    "recall_total = tp_total / (tp_total + fn_total) if (tp_total + fn_total) > 0 else 0\n",
    "f1_total = 2 * precision_total * recall_total / (precision_total + recall_total) if (precision_total + recall_total) > 0 else 0\n",
    "\n",
    "# Imprimir métricas globales\n",
    "print(f\"TP total: {tp_total}, FP total: {fp_total}, FN total: {fn_total}\")\n",
    "print(f\"Accuracy: {accuracy_total:.2f}\")\n",
    "print(f\"Precision: {precision_total:.2f}\")\n",
    "print(f\"Recall: {recall_total:.2f}\")\n",
    "print(f\"F1 Score: {f1_total:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
